# Awesome Audio Visual Question Answering:[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

<p align="center">
  <img width="250" src="https://camo.githubusercontent.com/1131548cf666e1150ebd2a52f44776d539f06324/68747470733a2f2f63646e2e7261776769742e636f6d2f73696e647265736f726875732f617765736f6d652f6d61737465722f6d656469612f6c6f676f2e737667" "Awesome!">
</p>

A curated list of **Audio Visual Question Answering(AVQA)** dataset and papers. AVQA is a task where a system analyzes both audio and visual elements in a video and a natural language question to produce an appropriate natural language answer.

## Contributing
Please feel free to send me [pull requests](https://github.com/swarupbehera/awesome-audio-visual-question-answering/pulls) or email (swarupranjanbehera@gmail.com) to add links.
Markdown format:

```markdown
- [Paper Name](link) - Author 1 et al, **Conference Year**. [[code]](link)
```

## Change Log

- v1: 2023-11-23

## Table of Contents
  * [Contributing](#contributing)
  * [Change Log](#change-log)
  * [Table of Contents](#table-of-contents)
  * [Dataset](#Dataset)
  * [Papers](#papers)
     * [2024](#2024)
        - [Arxiv 2024](#Arxiv-2022-1)
     * [2022](#2022)
        - [ECCV 2022](#ECCV-2022)
        - [CVPR 2022](#CVPR-2022)
        - [ACM Multimedia 2022](#ACM-Multimedia-2022)
    * [2021](#2021)
        - [ICCV 2022](#ICCV-2022)
  * [AVQA Challenge Leaderboard](#avqa-challenge-leaderboard)
  * [Licenses](#licenses)
  * [Reference and Acknowledgement](#reference-and-acknowledgement)

## Dataset
![AVQA Dataset Comparison](DC.png?raw=true "AVQA Dataset Comparison")
[Source](http://mn.cs.tsinghua.edu.cn/avqa/)
<!-- | Dataset | Number of Audios | Duration (hours) | Maximum Duration (seconds) | Average Duration (seconds) | Question-Answer Source | Language | Number of Questions | Number of Answers | Training Set Size | Validation Set Size | Test Set Size |
|---------|-----------------|------------------|----------------------------|----------------------------|-----------------------|----------|---------------------|-------------------|-------------------|---------------------|----------------|
| [ClothoAQA](https://zenodo.org/record/6473207) | 1991 | 12.44 | 30 | 21 | Crowdsourced | English | 9153 | 830 | 1174 | 344 | 473 |
| [CLEAR](https://ieee-dataport.org/open-access/clear-dataset-compositional-language-and-elementary-acoustic-reasoning) | 50000 | 3.12 | 0.4 | 0.25 | Programmatically Generated | English | 130957 | 47 | 35000 | 7500 | 7500 |
| [DAQA](https://github.com/facebookresearch/daqa) | 100000 | 2244.4 | 178.2 | 80.8 | Programmatically Generated | English | 599294 | 36 | 80000 | 10000 | 10000 | -->

## Papers

### 2024

#### Arxiv 2024
- [Boosting Audio Visual Question Answering via Key Semantic-Aware Cues](https://arxiv.org/pdf/2407.20693v1) - Guangyao Li et al. **ECCV**. [Code](https://github.com/gewu-lab/tspm).

### 2022

#### ECCV 2022
- [PACS: A Dataset for Physical Audiovisual CommonSense Reasoning](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136970286.pdf) - Samuel Yu et al. **ECCV**.

#### CVPR 2022
- [Learning To Answer Questions in Dynamic Audio-Visual Scenarios](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Learning_To_Answer_Questions_in_Dynamic_Audio-Visual_Scenarios_CVPR_2022_paper.pdf) - Guangyao Li et al., **CVPR**.

#### ACM-Multimedia 2022
- [AVQA: A Dataset for Audio-Visual Question Answering on Videos](https://dl.acm.org/doi/pdf/10.1145/3503161.3548291) - Pinci Yang et al., **ACM Multimedia**.

### 2021

#### ICCV 2021
- [Pano-AVQA: Grounded Audio-Visual Question Answering on 360 Degree Videos](https://openaccess.thecvf.com/content/ICCV2021/papers/Yun_Pano-AVQA_Grounded_Audio-Visual_Question_Answering_on_360deg_Videos_ICCV_2021_paper.pdf) - Heeseung Yun et al. **ICCV**.

## AVQA Challenge Leaderboard
Stay tuned...

## Licenses

[![CC0](http://i.creativecommons.org/p/zero/1.0/88x31.png)](http://creativecommons.org/publicdomain/zero/1.0/)

To the extent possible under law, [Swarup](https://github.com/swarupbehera/) has waived all copyright and related or neighboring rights to this work.

## Reference and Acknowledgement
